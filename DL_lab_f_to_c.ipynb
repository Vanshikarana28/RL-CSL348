{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vanshikarana28/RL-CSL348/blob/main/DL_lab_f_to_c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrxLeq8XKJ3T"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sbn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1W9A_u7pKffu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/02_Celsius to Fahrenheit (1).csv\")"
      ],
      "metadata": {
        "id": "9ECA5xOyNExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "df.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athMOz8BNfOS",
        "outputId": "377ab621-559d-446b-c57a-43e785afc01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Celsius  Fahrenheit\n",
            "0      -50       -58.0\n",
            "1      -40       -40.0\n",
            "2      -30       -22.0\n",
            "3      -20        -4.0\n",
            "4      -10        14.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Celsius', 'Fahrenheit'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "3-9yTScIOIK9",
        "outputId": "012bc7a2-4dad-4032-819f-d40e4bbb84a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Celsius  Fahrenheit\n",
              "0     False       False\n",
              "1     False       False\n",
              "2     False       False\n",
              "3     False       False\n",
              "4     False       False\n",
              "5     False       False\n",
              "6     False       False\n",
              "7     False       False\n",
              "8     False       False\n",
              "9     False       False\n",
              "10    False       False\n",
              "11    False       False\n",
              "12    False       False\n",
              "13    False       False\n",
              "14    False       False\n",
              "15    False       False\n",
              "16    False       False\n",
              "17    False       False\n",
              "18    False       False\n",
              "19    False       False\n",
              "20    False       False\n",
              "21    False       False\n",
              "22    False       False\n",
              "23    False       False\n",
              "24    False       False\n",
              "25    False       False\n",
              "26    False       False\n",
              "27    False       False\n",
              "28    False       False\n",
              "29    False       False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1773da3b-b77f-4a29-a72d-db1e529daf00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1773da3b-b77f-4a29-a72d-db1e529daf00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1773da3b-b77f-4a29-a72d-db1e529daf00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1773da3b-b77f-4a29-a72d-db1e529daf00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb0ebd01-a09b-4c6f-950b-649291e40a8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb0ebd01-a09b-4c6f-950b-649291e40a8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb0ebd01-a09b-4c6f-950b-649291e40a8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Celsius\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          false\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fahrenheit\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          false\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df['Fahrenheit']\n",
        "Y_train = df['Celsius']\n",
        "print(X_train.shape,\" \", Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtqW3mDZPLF8",
        "outputId": "d0b09156-675a-4c01-cb75-d728a0802a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30,)   (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units = 128, input_shape = (1,)))\n",
        "model.add(tf.keras.layers.Dense(units = 128))\n",
        "model.add(tf.keras.layers.Dense(units = 1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4LqYKv3Q-O6",
        "outputId": "f65c135f-194e-4eb1-8fc3-96aff410ae1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               256       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16897 (66.00 KB)\n",
            "Trainable params: 16897 (66.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= tf.keras.optimizers.Adam(1), loss = 'mean_squared_error')\n",
        "model.fit(X_train,Y_train, epochs = 200, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8fBUIntS5K8",
        "outputId": "0095a58d-9a06-4f05-e796-c40558921209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 231.9571 - val_loss: 33814766157824.0000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3847070154752.0000 - val_loss: 598975447040.0000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 70242574336.0000 - val_loss: 3974979911680.0000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 457122152448.0000 - val_loss: 371777824.0000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 44140560.0000 - val_loss: 1260126601216.0000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 142122680320.0000 - val_loss: 84363649024.0000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10537995264.0000 - val_loss: 3617642512384.0000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 420672438272.0000 - val_loss: 35715530752.0000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3720449024.0000 - val_loss: 2818347630592.0000\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 319861850112.0000 - val_loss: 274131779584.0000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 30650646528.0000 - val_loss: 1554326749184.0000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 179825557504.0000 - val_loss: 1517051052032.0000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 174851407872.0000 - val_loss: 3286935552.0000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 377728160.0000 - val_loss: 1000380301312.0000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 115344564224.0000 - val_loss: 779921063936.0000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 90359644160.0000 - val_loss: 592352896.0000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 123440256.0000 - val_loss: 672140951552.0000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 75912978432.0000 - val_loss: 791905239040.0000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 89350250496.0000 - val_loss: 57098809344.0000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6131400192.0000 - val_loss: 236581683200.0000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 28323112960.0000 - val_loss: 568391630848.0000\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 67133968384.0000 - val_loss: 202688823296.0000\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 24460240896.0000 - val_loss: 26636236800.0000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2747411456.0000 - val_loss: 385793130496.0000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 42859388928.0000 - val_loss: 314719240192.0000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 34858172416.0000 - val_loss: 10009027584.0000\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 995298816.0000 - val_loss: 129342726144.0000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 15791606784.0000 - val_loss: 266368778240.0000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 31858726912.0000 - val_loss: 101518761984.0000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 12426955776.0000 - val_loss: 4906381824.0000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 482941856.0000 - val_loss: 146199740416.0000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 16120886272.0000 - val_loss: 166756139008.0000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 18481498112.0000 - val_loss: 28232464384.0000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3007438080.0000 - val_loss: 18851444736.0000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2412037376.0000 - val_loss: 101289205760.0000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 12121973760.0000 - val_loss: 89717661696.0000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 10722394112.0000 - val_loss: 14293711872.0000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1799792000.0000 - val_loss: 11972178944.0000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1281042432.0000 - val_loss: 65834668032.0000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7353955840.0000 - val_loss: 60319989760.0000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 6754115584.0000 - val_loss: 10876204032.0000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1186079360.0000 - val_loss: 4920738816.0000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 614314496.0000 - val_loss: 34764337152.0000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4103343104.0000 - val_loss: 40473751552.0000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4751785472.0000 - val_loss: 14872787968.0000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1759291392.0000 - val_loss: 33254330.0000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3416178.7500 - val_loss: 14115619840.0000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1598722048.0000 - val_loss: 26943432704.0000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3074662400.0000 - val_loss: 16051544064.0000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1832939648.0000 - val_loss: 1242459520.0000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 140180240.0000 - val_loss: 3667190528.0000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 425647456.0000 - val_loss: 14157327360.0000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1633491968.0000 - val_loss: 14692379648.0000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1691496448.0000 - val_loss: 5317145088.0000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 609597888.0000 - val_loss: 1615142.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 354665.5938 - val_loss: 4596465664.0000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 536514336.0000 - val_loss: 9628839936.0000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1121576576.0000 - val_loss: 6743558144.0000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 788466432.0000 - val_loss: 1026335744.0000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 123198040.0000 - val_loss: 691954944.0000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76133120.0000 - val_loss: 4571509760.0000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 516753504.0000 - val_loss: 5970528256.0000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 676045248.0000 - val_loss: 3003299072.0000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 337266016.0000 - val_loss: 149726096.0000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15534765.0000 - val_loss: 973526784.0000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 118552520.0000 - val_loss: 3246436608.0000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 385649568.0000 - val_loss: 3075719168.0000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 365730944.0000 - val_loss: 898842688.0000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 109813096.0000 - val_loss: 35095984.0000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3449954.0000 - val_loss: 1291208960.0000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 142861520.0000 - val_loss: 2330364928.0000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 260598208.0000 - val_loss: 1572397440.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 174808000.0000 - val_loss: 241707824.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 25609718.0000 - val_loss: 159381872.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20978374.0000 - val_loss: 1051661312.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 127162456.0000 - val_loss: 1291088896.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 155179824.0000 - val_loss: 533206944.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 65509456.0000 - val_loss: 1424329.6250\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 676550.6875 - val_loss: 373802848.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 40612860.0000 - val_loss: 883471104.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 98044576.0000 - val_loss: 702643968.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 77760168.0000 - val_loss: 151330640.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16113343.0000 - val_loss: 33182176.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4759778.5000 - val_loss: 373960320.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 45620468.0000 - val_loss: 516041376.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 62258224.0000 - val_loss: 233801280.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 28756384.0000 - val_loss: 2183204.2500\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 544262.0625 - val_loss: 140373808.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 15206859.0000 - val_loss: 349608864.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 38790772.0000 - val_loss: 275379328.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 30490110.0000 - val_loss: 53147328.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5651572.5000 - val_loss: 18869280.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2569658.7500 - val_loss: 161905024.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19606482.0000 - val_loss: 202305040.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 24289470.0000 - val_loss: 76857512.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9424152.0000 - val_loss: 171498.4531\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 39402.0312 - val_loss: 74038816.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8154844.0000 - val_loss: 145034864.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16222081.0000 - val_loss: 90851776.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10117120.0000 - val_loss: 7798048.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 816379.6875 - val_loss: 20968854.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2586849.2500 - val_loss: 80367352.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9550138.0000 - val_loss: 72227768.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8566403.0000 - val_loss: 14903775.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1816832.6250 - val_loss: 5168390.5000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 556071.7500 - val_loss: 45394996.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5123169.5000 - val_loss: 55999492.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6351664.0000 - val_loss: 20051100.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2259378.7500 - val_loss: 202623.1875\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 29501.0488 - val_loss: 21731462.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2545829.2500 - val_loss: 37188808.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4328300.5000 - val_loss: 18370846.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2138406.2500 - val_loss: 206463.8750\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 25194.2891 - val_loss: 10533122.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1210861.1250 - val_loss: 24274198.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2800481.2500 - val_loss: 15288257.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1768673.3750 - val_loss: 929339.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 109598.5703 - val_loss: 4874789.5000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 555036.4375 - val_loss: 15434852.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1764047.5000 - val_loss: 11750117.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1338597.2500 - val_loss: 1384618.1250\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 153509.5312 - val_loss: 2153530.5000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 258134.2656 - val_loss: 9376708.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1102861.0000 - val_loss: 8147498.5000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 960873.3125 - val_loss: 1256154.1250\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 154019.4219 - val_loss: 1139808.8750\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 124138.7891 - val_loss: 6179952.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 694256.4375 - val_loss: 5927472.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 665278.1250 - val_loss: 1161927.5000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 126323.3125 - val_loss: 517588.5000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 66413.9609 - val_loss: 3719713.7500\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 445408.2500 - val_loss: 3757862.7500\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 449703.3438 - val_loss: 730967.1875\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 91857.6641 - val_loss: 382938.5000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 40293.7422 - val_loss: 2634630.2500\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 292608.8125 - val_loss: 2681872.7500\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 298263.9062 - val_loss: 555827.9375\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 59606.7812 - val_loss: 216141.5469\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 28735.6895 - val_loss: 1633144.6250\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 197286.6719 - val_loss: 1610600.6250\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 194232.3125 - val_loss: 271063.6562\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 34852.7656 - val_loss: 220138.7656\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 23213.2480 - val_loss: 1225222.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 135863.0156 - val_loss: 1114860.2500\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 123671.3984 - val_loss: 167420.1406\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17711.1230 - val_loss: 161278.5625\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 20654.7754 - val_loss: 788572.8125\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 94846.8125 - val_loss: 633933.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76347.6328 - val_loss: 55142.1875\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7358.7847 - val_loss: 176415.5625\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19149.8066 - val_loss: 593484.9375\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 66331.9609 - val_loss: 404017.1250\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 45016.4883 - val_loss: 19853.4688\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2036.3444 - val_loss: 147537.2969\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17921.0527 - val_loss: 386521.7812\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 45830.4102 - val_loss: 207916.9375\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 24799.0215 - val_loss: 666.2444\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 146.3469 - val_loss: 146194.3281\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16401.8223 - val_loss: 271326.3750\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 30764.6191 - val_loss: 108898.8516\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12280.6514 - val_loss: 1827.3765\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 248.8225 - val_loss: 123256.1172\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 14417.6729 - val_loss: 168922.0781\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19657.8574 - val_loss: 43725.5352\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5104.0078 - val_loss: 10828.6660\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1232.3842 - val_loss: 103869.3359\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11967.6240 - val_loss: 100819.8359\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11651.7529 - val_loss: 12886.8604\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1504.5068 - val_loss: 20358.4863\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2314.7532 - val_loss: 80858.2812\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9239.6045 - val_loss: 54174.7188\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6163.8989 - val_loss: 1526.4122\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 162.0672 - val_loss: 25485.0605\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3018.0918 - val_loss: 55459.6758\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6521.5488 - val_loss: 22863.1816\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2722.8821 - val_loss: 568.7637\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 56.7374 - val_loss: 28234.0684\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3163.6711 - val_loss: 36436.9062\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4094.4368 - val_loss: 7905.9941\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 864.3973 - val_loss: 3529.2520\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 448.3453 - val_loss: 23334.8027\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2788.2415 - val_loss: 18232.2090\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2189.7671 - val_loss: 809.1652\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 115.2894 - val_loss: 7776.3906\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 851.5301 - val_loss: 18708.5703\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2083.8555 - val_loss: 8336.7412\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 916.4539 - val_loss: 80.2242\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.9646 - val_loss: 8455.7354\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1025.2727 - val_loss: 10782.4072\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1296.8776 - val_loss: 1880.1270\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 239.8230 - val_loss: 1738.3861\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 185.6701 - val_loss: 8381.9238\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 932.7106 - val_loss: 5732.4858\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 634.0408 - val_loss: 121.9535\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.8768 - val_loss: 2896.4778\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 353.6299 - val_loss: 5568.8804\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 665.9565 - val_loss: 1704.6324\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 209.5452 - val_loss: 323.8192\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 33.7549 - val_loss: 3580.2219\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 399.8287 - val_loss: 3236.9265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d1a68ed4af0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DisS_pzHUzjv",
        "outputId": "bffa1944-9116-422c-8dcb-902b4798bf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-4.6057079e-02,  2.7618408e-01, -5.9126196e-05,  2.5495491e+00,\n",
              "          1.2156948e+00, -9.2655480e-02, -4.6107233e-01,  6.8361327e-02,\n",
              "         -1.9283391e-03,  1.3827702e+00, -1.1887633e+00, -1.8102002e-01,\n",
              "          1.0501891e-01,  2.1240389e+00,  5.9637696e-01,  1.1794158e+00,\n",
              "         -9.7162539e-01, -2.7165961e-02, -1.1009495e+00, -1.4317017e+00,\n",
              "          6.2079359e-02,  2.5588915e-02, -2.4746666e-02, -1.4088701e+00,\n",
              "         -7.5928110e-01,  3.9054621e-03, -3.8728442e-03,  4.8792433e-02,\n",
              "          1.6160876e+00, -1.0740945e+00, -1.4264081e+00, -9.0981174e-01,\n",
              "         -2.5781279e+00, -1.4618278e+00, -1.1141242e-02,  4.2429123e-02,\n",
              "         -7.4064888e-02,  3.1911472e-03, -3.3609840e-01,  1.5823042e+00,\n",
              "         -1.6474422e+00, -6.4594096e-01,  1.7675444e+00,  1.2224656e+00,\n",
              "         -1.8340217e+00,  1.2628495e+00,  2.3409410e+00,  5.9645152e-01,\n",
              "          1.6382148e-02, -1.5121217e-02,  1.2012311e-02, -3.5767812e-02,\n",
              "         -1.6684249e-02, -2.5667658e+00, -1.4237223e+00,  6.7102410e-02,\n",
              "         -1.7303758e+00, -1.6707116e-01,  4.0363602e-02, -4.2214565e-02,\n",
              "          4.7390187e-01, -1.2932190e+00, -2.9900050e-02, -2.4728488e-02,\n",
              "         -2.8029861e-02, -4.7479691e-03,  3.7544686e-02,  4.5196161e-02,\n",
              "         -2.0557481e-01, -1.1807470e+00, -2.5751390e+00, -3.3856437e-02,\n",
              "         -1.6883966e+00, -1.4037629e+00,  1.3248401e-02, -4.5830435e-01,\n",
              "          1.6124586e-02,  4.9792740e-02,  1.5949725e+00, -1.4908433e+00,\n",
              "          7.0719235e-02, -1.2049159e+00,  9.0637192e-02, -7.8182387e-01,\n",
              "         -5.6486350e-01, -1.7933755e-01,  1.4112482e-02,  8.7999860e-03,\n",
              "          3.0188304e-01, -1.5770842e+00, -1.5876061e+00,  5.6600583e-01,\n",
              "         -1.4587724e+00, -9.0395063e-03,  2.2912676e-02, -5.9745836e-01,\n",
              "         -1.5355976e+00,  4.2754550e-02, -1.6675508e+00, -8.3865523e-03,\n",
              "          2.5381774e-01, -4.5431726e-02,  1.5701041e+00, -1.9004613e-02,\n",
              "          3.1733226e-02,  1.9184113e-02, -1.6398300e+00,  2.1140609e-02,\n",
              "         -7.8268886e-02,  2.5609260e+00, -2.7399853e-01,  2.9909795e-02,\n",
              "         -2.6697010e-01,  9.8552442e-01,  2.6643798e-02, -1.4604728e+00,\n",
              "          1.2450296e-02,  1.3591086e+00,  2.5666859e+00, -1.4644004e-02,\n",
              "          1.5724720e+00,  2.2473866e-02, -3.7778386e-01, -2.5542133e+00,\n",
              "         -1.0430778e-02, -1.7389439e+00, -1.8229454e+00,  1.2106349e+00]],\n",
              "       dtype=float32),\n",
              " array([ 1.5676839 , -1.1593128 ,  1.5934591 ,  2.6249793 , -1.4791188 ,\n",
              "         1.3768278 , -0.78969777, -1.4211607 , -1.6232866 ,  1.613739  ,\n",
              "        -1.4467132 ,  2.7212744 , -1.3810024 ,  2.3335664 ,  3.4110448 ,\n",
              "         3.8672462 , -1.21836   , -1.6609291 , -1.3732729 , -2.1859534 ,\n",
              "        -1.4244258 , -1.6222731 ,  1.5856268 , -1.660855  , -3.5131147 ,\n",
              "        -1.6308073 , -1.6424407 , -1.6017478 , -1.097508  , -1.3167865 ,\n",
              "        -2.1711974 , -3.667556  , -2.678658  , -1.6912543 ,  1.6208824 ,\n",
              "        -1.570678  ,  1.4262202 ,  1.4982444 ,  1.1004157 ,  1.5977453 ,\n",
              "         1.2595217 , -0.91646767, -1.1054678 ,  3.896902  , -1.8302181 ,\n",
              "         3.9230037 ,  2.5389104 ,  0.8760101 ,  1.587981  , -1.6380926 ,\n",
              "        -1.6219913 ,  1.5075215 ,  1.6334909 , -2.7126455 , -2.1674557 ,\n",
              "        -1.4165362 ,  1.0343324 ,  1.2351288 ,  1.6570072 , -1.6121666 ,\n",
              "         0.80112153, -3.9328854 ,  1.609883  ,  1.5927445 ,  1.5573695 ,\n",
              "        -1.6120303 , -1.4926972 , -1.4760137 ,  1.2131855 , -3.8549004 ,\n",
              "        -2.7101538 ,  1.6061082 ,  1.1981149 , -2.1727505 , -1.5745984 ,\n",
              "        -3.2608643 ,  1.6228259 , -1.4477423 , -1.3537347 , -1.5195664 ,\n",
              "        -1.4253088 ,  1.677462  , -1.3931284 , -3.549302  , -3.330216  ,\n",
              "         1.240549  ,  1.6375722 ,  1.659376  , -1.1077974 ,  1.1677727 ,\n",
              "        -1.583662  , -2.3610005 , -3.9348397 , -1.5849088 ,  1.6556463 ,\n",
              "        -0.8639797 , -1.55292   , -1.5076178 , -1.6894221 ,  1.6312995 ,\n",
              "        -1.1767097 ,  1.6083156 ,  1.8064055 ,  1.6154413 ,  1.593284  ,\n",
              "        -1.5377471 ,  1.2914819 ,  1.6269468 ,  1.571175  ,  2.6782877 ,\n",
              "         1.1275821 ,  1.6022183 ,  1.1459782 ,  1.2415819 ,  1.682769  ,\n",
              "        -1.4918157 ,  1.6377051 ,  2.1672308 ,  2.6901975 , -1.6265445 ,\n",
              "        -1.1322166 ,  1.6250589 ,  1.0101329 , -2.6987023 , -1.567326  ,\n",
              "         1.11657   , -1.8419626 ,  3.8819134 ], dtype=float32),\n",
              " array([[ 2.4589171 , -0.68347   ,  1.8510544 , ..., -0.37485984,\n",
              "         -1.802781  ,  0.75123185],\n",
              "        [-2.5170312 ,  2.0432422 , -1.4983965 , ...,  0.52934104,\n",
              "          1.4430567 , -2.0097098 ],\n",
              "        [ 3.081481  , -1.2130723 ,  2.1965306 , ..., -0.9163087 ,\n",
              "         -2.2448142 ,  0.86026907],\n",
              "        ...,\n",
              "        [-6.8550253 , -5.567291  , -6.8275084 , ...,  3.4695406 ,\n",
              "          6.8770227 ,  5.669156  ],\n",
              "        [ 1.7694118 ,  0.5274875 ,  1.3585976 , ..., -2.5692668 ,\n",
              "         -1.3358352 , -0.64758325],\n",
              "        [-5.5984254 , -5.7436705 , -6.5237737 , ..., -0.46653274,\n",
              "          6.2771654 ,  5.352866  ]], dtype=float32),\n",
              " array([  5.7862096,   6.7969394,   6.6850624,  -4.3873005,   4.2968097,\n",
              "          6.8018274,  -6.7053494,  -4.7932253,   4.148674 ,   4.247194 ,\n",
              "         -6.6712728,   2.2227166,   4.2642226,   4.2942677,  -7.3568816,\n",
              "         -4.3530517,  -6.9852276,   6.7897396,   5.406799 ,  -4.1534877,\n",
              "          6.497084 ,   6.271946 ,  -7.1247196,   7.2365065,  -7.3266478,\n",
              "         -2.9275095,  -6.9311996,  -6.7367845, -12.609139 ,   4.260378 ,\n",
              "         -6.512783 ,  -4.24669  ,   6.3701167,   4.2880607,   4.310773 ,\n",
              "         -6.3521156, -13.001319 ,  12.83807  ,   6.1292586,  -7.364411 ,\n",
              "         -6.7160544,   6.888959 ,  -6.6267447,  -4.3664713,  -4.317486 ,\n",
              "        -12.533289 ,  12.421753 ,  -7.403131 ,  -4.5400767,   7.4241085,\n",
              "         -6.6662946,   7.473702 ,   4.322065 ,  -4.2590075,  -6.1634192,\n",
              "          4.2395716,  -6.731316 ,  -7.30858  ,  -4.33785  ,   6.590591 ,\n",
              "          6.721985 ,  13.002632 ,   7.024609 ,   6.67926  ,  -6.853179 ,\n",
              "        -12.931024 ,   7.5493197,   4.280945 ,   4.174819 ,  -4.4394035,\n",
              "          6.0449586,   7.13275  ,   4.1846786,  -7.487036 ,  -6.906994 ,\n",
              "        -13.0915575,   7.5510044,  -4.496864 ,   6.709262 ,   6.1056943,\n",
              "         -6.5757065,  -9.987038 ,   7.2190537, -12.410344 ,  -7.4259386,\n",
              "        -12.767377 ,   2.523297 ,   4.331981 ,  -4.851026 ,   4.1169157,\n",
              "         -6.6996627,  -7.4587097,  -4.263624 ,  -7.2453732,  -7.498709 ,\n",
              "          7.9203777,   6.3073525,  -6.7032695,  -2.2982492,   4.3102345,\n",
              "          4.5336823,  -4.425649 ,  -6.5993457,  -7.557729 ,  -5.44011  ,\n",
              "          6.9124784,  -7.4344473,   4.12205  ,  12.643305 ,  -6.7557306,\n",
              "          6.80892  ,   4.5338683,  12.522094 ,   6.763041 ,  -6.462908 ,\n",
              "         -4.8692813,   6.2560654, -13.080769 ,   6.889459 ,  -4.344073 ,\n",
              "         -7.2362113,  -2.4886277,  -4.3515053,  -6.443574 ,   7.2567544,\n",
              "          4.3477197,  -6.7810946,  -6.9622707], dtype=float32),\n",
              " array([[-2.0952547e-01],\n",
              "        [ 5.3347595e-02],\n",
              "        [-5.4827169e-02],\n",
              "        [ 2.6267323e-01],\n",
              "        [-3.1695515e-01],\n",
              "        [ 5.0514437e-02],\n",
              "        [ 7.4932195e-02],\n",
              "        [ 2.6855823e-01],\n",
              "        [-2.5799361e-01],\n",
              "        [-3.5114059e-01],\n",
              "        [ 1.0746899e-01],\n",
              "        [ 2.7319908e-02],\n",
              "        [-2.4206564e-01],\n",
              "        [-2.6868913e-01],\n",
              "        [-8.5406583e-03],\n",
              "        [ 3.0534413e-01],\n",
              "        [-8.3726841e-01],\n",
              "        [ 4.8655894e-02],\n",
              "        [-2.1542992e-01],\n",
              "        [ 2.6232541e-01],\n",
              "        [-1.2879583e-01],\n",
              "        [-1.5439005e-01],\n",
              "        [-1.7788952e-02],\n",
              "        [ 1.4247454e-02],\n",
              "        [-3.0560174e-03],\n",
              "        [-2.8785166e-01],\n",
              "        [-8.0425787e-01],\n",
              "        [-7.2637849e-02],\n",
              "        [ 1.4040980e+00],\n",
              "        [-3.1188223e-01],\n",
              "        [ 1.2956962e-01],\n",
              "        [ 2.7027443e-01],\n",
              "        [-1.5121636e-01],\n",
              "        [-3.4246913e-01],\n",
              "        [-3.2348180e-01],\n",
              "        [ 1.3941638e-01],\n",
              "        [ 1.3606614e+00],\n",
              "        [-1.3172121e+00],\n",
              "        [-1.6241011e-01],\n",
              "        [-7.5321078e-01],\n",
              "        [ 4.5694269e-02],\n",
              "        [ 8.2511264e-01],\n",
              "        [ 9.7355813e-02],\n",
              "        [ 2.8997484e-01],\n",
              "        [ 2.5508934e-01],\n",
              "        [ 1.3889189e+00],\n",
              "        [-1.3698554e+00],\n",
              "        [-9.3926014e-03],\n",
              "        [ 2.9386246e-01],\n",
              "        [ 7.2047108e-01],\n",
              "        [-7.7078857e-02],\n",
              "        [ 7.0064777e-01],\n",
              "        [-2.5593862e-01],\n",
              "        [ 2.5157163e-01],\n",
              "        [ 1.6732876e-01],\n",
              "        [-3.3671427e-01],\n",
              "        [-7.3594135e-01],\n",
              "        [-7.1463326e-04],\n",
              "        [ 2.8071186e-01],\n",
              "        [-2.5577065e-02],\n",
              "        [ 6.9960229e-02],\n",
              "        [-1.3404391e+00],\n",
              "        [ 3.1575885e-02],\n",
              "        [-5.3628832e-02],\n",
              "        [-9.5551005e-03],\n",
              "        [ 1.3230755e+00],\n",
              "        [ 5.1200467e-01],\n",
              "        [-3.4319404e-01],\n",
              "        [-2.4120775e-01],\n",
              "        [ 2.7517018e-01],\n",
              "        [-1.6357811e-01],\n",
              "        [ 3.3993556e-03],\n",
              "        [-2.8113037e-01],\n",
              "        [-5.6788021e-01],\n",
              "        [ 6.6173367e-02],\n",
              "        [ 1.3058046e+00],\n",
              "        [ 5.2201307e-01],\n",
              "        [ 2.9663756e-01],\n",
              "        [ 7.2520398e-02],\n",
              "        [-1.6330285e-01],\n",
              "        [ 1.2387294e-01],\n",
              "        [-1.9464326e-01],\n",
              "        [ 1.6871184e-02],\n",
              "        [ 1.3803315e+00],\n",
              "        [-6.7952931e-01],\n",
              "        [ 1.3455279e+00],\n",
              "        [ 1.2174530e-01],\n",
              "        [-2.6146913e-01],\n",
              "        [ 2.5767845e-01],\n",
              "        [-3.8013777e-01],\n",
              "        [-7.7567868e-02],\n",
              "        [-5.1657397e-01],\n",
              "        [ 3.2207718e-01],\n",
              "        [-5.6956308e-03],\n",
              "        [-5.1691759e-01],\n",
              "        [ 3.2394469e-01],\n",
              "        [-5.2714668e-02],\n",
              "        [ 3.0435000e-03],\n",
              "        [ 5.1044382e-02],\n",
              "        [-2.5841016e-01],\n",
              "        [-2.8255236e-01],\n",
              "        [ 2.8039816e-01],\n",
              "        [-8.6181886e-02],\n",
              "        [-6.9157803e-01],\n",
              "        [ 2.1685326e-01],\n",
              "        [ 4.5305792e-02],\n",
              "        [-7.4242228e-01],\n",
              "        [-3.6477563e-01],\n",
              "        [-1.3881458e+00],\n",
              "        [ 3.4385424e-02],\n",
              "        [ 4.6529882e-02],\n",
              "        [-2.9497662e-01],\n",
              "        [-1.3710587e+00],\n",
              "        [ 7.0575334e-02],\n",
              "        [ 1.3940829e-01],\n",
              "        [ 2.5918302e-01],\n",
              "        [-1.6037627e-01],\n",
              "        [ 1.3397279e+00],\n",
              "        [-2.1921797e-02],\n",
              "        [ 2.8064600e-01],\n",
              "        [-1.4252715e-02],\n",
              "        [-1.4173770e-01],\n",
              "        [ 2.5266773e-01],\n",
              "        [ 1.4164318e-01],\n",
              "        [ 4.9653561e-03],\n",
              "        [-3.1616199e-01],\n",
              "        [ 7.5380594e-02],\n",
              "        [-2.8267829e-02]], dtype=float32),\n",
              " array([-6.29044], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Temp_F = 32\n",
        "Temp_C = model.predict([Temp_F])\n",
        "print(Temp_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rlrFW-eU_Wd",
        "outputId": "a0f1792a-4b47-4de4-d6ed-1259f4445417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "[[-14.050647]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Temp_C = 5/9 *( Temp_F - 32)\n",
        "print('Temprature in Fahrenheit using normal equation=', Temp_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OEkNO5DVVhf",
        "outputId": "8e4184b2-3a21-469a-f2bc-0e07404be66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temprature in Fahrenheit using normal equation= 0.0\n"
          ]
        }
      ]
    }
  ]
}